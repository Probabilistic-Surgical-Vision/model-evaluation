{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "from model import RandomlyConnectedModel\n",
    "\n",
    "from evaluation.hamlyn import evaluate_ssim\n",
    "from evaluation.scared import evaluate_keyframes\n",
    "from evaluation.utils import prepare_state_dict\n",
    "from evaluation import sparsification as s\n",
    "from evaluation import transforms as t\n",
    "\n",
    "from loaders.hamlyn import HamlynDataset\n",
    "from loaders.scared import SCAREDKeyframesLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'uncertainty-l1.pt'\n",
    "model_config = 'uncertainty-config.yml'\n",
    "\n",
    "datasets_path = '../datasets/'\n",
    "hamlyn_path = os.path.join(datasets_path, 'da-vinci')\n",
    "scared_path = os.path.join(datasets_path, 'scared')\n",
    "\n",
    "batch_size = 8\n",
    "min_depth = 4.676 # mm\n",
    "max_depth = 180.554 # mm\n",
    "\n",
    "save_to = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') \\\n",
    "    if torch.cuda.is_available() \\\n",
    "    else torch.device('cpu')\n",
    "\n",
    "print(f'Using CUDA? {\"cuda\" in repr(device)}')\n",
    "\n",
    "with open(model_config) as f:\n",
    "    config = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "model = RandomlyConnectedModel(**config).to(device)\n",
    "\n",
    "model_stem = os.path.splitext(model_name)[0]\n",
    "model_save_to = os.path.join('results', model_stem)\n",
    "\n",
    "hamlyn_transform = transforms.Compose([\n",
    "    t.ResizeImage((256, 512)),\n",
    "    t.ToTensor()\n",
    "])\n",
    "\n",
    "scared_transform = transforms.Compose([\n",
    "    t.ResizeImage((1024, 1280)),\n",
    "    t.ToTensor()\n",
    "])\n",
    "\n",
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamlyn SSIM/Sparsification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlyn_model_path = os.path.join('models', 'hamlyn', model_name)\n",
    "hamlyn_save_to = os.path.join(model_save_to, 'hamlyn')\n",
    "\n",
    "state_dict = torch.load(hamlyn_model_path, map_location=device)\n",
    "state_dict = prepare_state_dict(state_dict)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "hamlyn_dataset = HamlynDataset(hamlyn_path, 'test', hamlyn_transform)\n",
    "hamlyn_dataloader = DataLoader(hamlyn_dataset, batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Hamlyn Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SSIM Evaluation:   0%|          | 0/899 [00:00<?, ?batch/s]/Users/louismanestar/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/functional.py:4215: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "SSIM Evaluation:   1%|          | 7/899 [00:41<1:27:55,  5.91s/batch, left=0.622, right=0.604]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/louismanestar/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/evaluate.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/louismanestar/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc%20Artificial%20Intelligence/Master%27s%20Project/repos/model-evaluation/evaluate.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ssims, spars \u001b[39m=\u001b[39m evaluate_ssim(model, hamlyn_dataloader, hamlyn_save_to, device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/evaluation/hamlyn.py:45\u001b[0m, in \u001b[0;36mevaluate_ssim\u001b[0;34m(model, loader, save_results_to, ssim_weight, device, no_pbar)\u001b[0m\n\u001b[1;32m     42\u001b[0m left \u001b[39m=\u001b[39m image_pair[\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     43\u001b[0m right \u001b[39m=\u001b[39m image_pair[\u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 45\u001b[0m prediction \u001b[39m=\u001b[39m model(left)\n\u001b[1;32m     46\u001b[0m pred_disp, pred_error \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msplit(prediction, [\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m left_disp, right_disp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msplit(pred_disp, [\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/model/model.py:19\u001b[0m, in \u001b[0;36mRandomlyConnectedModel.forward\u001b[0;34m(self, image, scale)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, image: Tensor, scale: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DecoderOut:\n\u001b[1;32m     18\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(image)\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(image, \u001b[39m*\u001b[39;49mencodings, scale\u001b[39m=\u001b[39;49mscale)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/model/decoder.py:32\u001b[0m, in \u001b[0;36mDepthDecoder.forward\u001b[0;34m(self, left_image, scale, *feature_maps)\u001b[0m\n\u001b[1;32m     28\u001b[0m f1, f2, f3, f4, x4 \u001b[39m=\u001b[39m feature_maps\n\u001b[1;32m     30\u001b[0m out5, skip5, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](x4, f4, x4, scale\u001b[39m=\u001b[39mscale)\n\u001b[0;32m---> 32\u001b[0m out4, skip4, disp4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[\u001b[39m1\u001b[39;49m](out5, f3, skip5, scale\u001b[39m=\u001b[39;49mscale)\n\u001b[1;32m     33\u001b[0m out3, skip3, disp3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m2\u001b[39m](out4, f2, skip4, disp4, scale)\n\u001b[1;32m     34\u001b[0m out2, skip2, disp2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m3\u001b[39m](out3, f1, skip3, disp3, scale)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/model/layers/decoder.py:151\u001b[0m, in \u001b[0;36mDecoderStage.forward\u001b[0;34m(self, x, feature_map, skip, disparity, scale)\u001b[0m\n\u001b[1;32m    146\u001b[0m     disparity \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39minterpolate(disparity, scale_factor\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale,\n\u001b[1;32m    147\u001b[0m                               align_corners\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    149\u001b[0m     x_concat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x_concat, disparity), \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 151\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miconv(x_concat)\n\u001b[1;32m    153\u001b[0m disparity \u001b[39m=\u001b[39m scale \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisp(out) \\\n\u001b[1;32m    154\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalculate_disp \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mreturn\u001b[39;00m out, skip, disparity\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/model/layers/decoder.py:53\u001b[0m, in \u001b[0;36mConvELUBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(x)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/model/layers/decoder.py:34\u001b[0m, in \u001b[0;36mConvLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding(x)\n\u001b[0;32m---> 34\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(x)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ssims, spars = evaluate_ssim(model, hamlyn_dataloader, hamlyn_save_to, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSIM Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ssim = np.mean(ssims)\n",
    "std_ssim = np.std(ssims)\n",
    "\n",
    "print('Hamlyn test set SSIM:'\n",
    "      f'\\n\\t- Mean: {mean_ssim}'\n",
    "      f'\\n\\t- Std. Deviation: {std_ssim}')\n",
    "\n",
    "results_dict['ssim'] = {\n",
    "    'mean': mean_ssim,\n",
    "    'std': std_ssim\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparsification Plot and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_curves, oracle_curves, random_curves = zip(*spars)\n",
    "\n",
    "pred_curve = np.array(pred_curves).mean(axis=0)\n",
    "oracle_curve = np.array(oracle_curves).mean(axis=0)\n",
    "random_curve = np.array(random_curves).mean(axis=0)\n",
    "\n",
    "error_curve = s.sparsification_error(oracle_curve, pred_curve)\n",
    "\n",
    "ause = s.ause(oracle_curve, pred_curve)\n",
    "aurg = s.aurg(pred_curve, random_curve)\n",
    "\n",
    "figure, (curve_axis, error_axis) = plt.subplots(2, 0)\n",
    "\n",
    "x_axis = np.linspace(0, 1, num=len(oracle_curve))\n",
    "\n",
    "curve_axis.plot(x_axis, oracle_curve, 'r-')\n",
    "curve_axis.plot(x_axis, pred_curve)\n",
    "\n",
    "error_axis.plot(x_axis, error_curve)\n",
    "\n",
    "print('Hamlyn test set Sparsification:'\n",
    "      f'\\n\\t- AUSE: {ause}'\n",
    "      f'\\n\\t- AURG: {aurg}')\n",
    "\n",
    "results_dict['sparsification'] = {\n",
    "    'ause': ause,\n",
    "    'aurg': aurg,\n",
    "    'curves': {\n",
    "        'oracle': oracle_curve,\n",
    "        'predicted': pred_curve,\n",
    "        'random': random_curve,\n",
    "        'error': error_curve\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCARED MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of SCARED Dataset 8: 5 images.\n",
      "Size of SCARED Dataset 9: 5 images.\n"
     ]
    }
   ],
   "source": [
    "scared_model_path = os.path.join('models', 'hamlyn', model_name)\n",
    "scared_save_to = os.path.join(model_save_to, 'scared')\n",
    "\n",
    "state_dict = torch.load(scared_model_path, map_location=device)\n",
    "state_dict = prepare_state_dict(state_dict)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "scared_dataset_8 = SCAREDKeyframesLoader(scared_path, 'test', 8, scared_transform)\n",
    "scared_dataloader_8 = DataLoader(scared_dataset_8, 1)\n",
    "\n",
    "print(f'Size of SCARED Dataset 8: {len(scared_dataset_8):,} images.')\n",
    "\n",
    "scared_dataset_9 = SCAREDKeyframesLoader(scared_path, 'test', 9, scared_transform)\n",
    "scared_dataloader_9 = DataLoader(scared_dataset_9, 1)\n",
    "\n",
    "print(f'Size of SCARED Dataset 9: {len(scared_dataset_9):,} images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SCARED Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:23<00:00,  4.63s/batch, mae=tensor(50.6697, dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 8 Keyframe MAEs: [27.28447265338262, 25.89122560226983, 9.90304156224073, 65.7162050259811, 124.55368446595801] mm\n",
      "Mean Absolute Depth on SCARED Dataset 8: 50.669725861966455 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.41s/batch, mae=tensor(76.4943, dtype=torch.float64)] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 9 Keyframe MAEs: [133.9774889871548, 21.60393080556474, 139.509304119105, 12.476071569642508, 74.90452305256555] mm\n",
      "Mean Absolute Depth on SCARED Dataset 9: 76.4942637068065 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "maes_8 = evaluate_keyframes(model, scared_dataloader_8, min_depth, max_depth, device)\n",
    "mean_mae_8 = sum(maes_8) / len(maes_8)\n",
    "print(f'Dataset 8 Keyframe MAEs: {maes_8} mm')\n",
    "print(f'Mean Absolute Depth on SCARED Dataset 8: {mean_mae_8} mm')\n",
    "\n",
    "maes_9 = evaluate_keyframes(model, scared_dataloader_9, min_depth, max_depth, device)\n",
    "mean_mae_9 = sum(maes_9) / len(maes_9)\n",
    "print(f'Dataset 9 Keyframe MAEs: {maes_9} mm')\n",
    "print(f'Mean Absolute Depth on SCARED Dataset 9: {mean_mae_9} mm')\n",
    "\n",
    "results_dict['mae'] = {\n",
    "    'dataset_8': mean_mae_8,\n",
    "    'dataset_9': mean_mae_9\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_path = os.path.join(save_to, model_stem, 'evaluation.json')\n",
    "\n",
    "with open(save_to_path, 'w+') as f:\n",
    "    json.dump(results_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "150b7516945f7222b22aa671f605619702d7b517da28017881bdfb428ff034ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
