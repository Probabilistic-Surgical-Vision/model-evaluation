{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "from model import RandomlyConnectedModel\n",
    "\n",
    "from evaluation.hamlyn import evaluate_ssim\n",
    "from evaluation.scared import evaluate_keyframes\n",
    "from evaluation.utils import prepare_state_dict\n",
    "from evaluation import sparsification as s\n",
    "from evaluation import transforms as t\n",
    "\n",
    "from loaders.hamlyn import HamlynDataset\n",
    "from loaders.scared import SCAREDKeyframesLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'uncertainty-l1.pt'\n",
    "model_config = 'uncertainty-config.yml'\n",
    "hamlyn_path = '../datasets/da-vinci'\n",
    "scared_path = '/Users/louismanestar/Desktop/scared-converted'\n",
    "batch_size = 8\n",
    "\n",
    "min_depth = 4.676 # mm\n",
    "max_depth = 180.554 # mm\n",
    "\n",
    "save_to = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') \\\n",
    "    if torch.cuda.is_available() \\\n",
    "    else torch.device('cpu')\n",
    "\n",
    "with open(model_config) as f:\n",
    "    config = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "model = RandomlyConnectedModel(**config).to(device)\n",
    "\n",
    "model_stem = os.path.splitext(model_name)[0]\n",
    "model_save_to = os.path.join('results', model_stem)\n",
    "\n",
    "hamlyn_transform = transforms.Compose([\n",
    "    t.ResizeImage((256, 512)),\n",
    "    t.ToTensor()\n",
    "])\n",
    "\n",
    "scared_transform = transforms.Compose([\n",
    "    t.ResizeImage((1024, 1280)),\n",
    "    t.ToTensor()\n",
    "])\n",
    "\n",
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamlyn SSIM/Sparsification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlyn_model_path = os.path.join('models', 'hamlyn', model_name)\n",
    "hamlyn_save_to = os.path.join(model_save_to, 'hamlyn')\n",
    "\n",
    "state_dict = torch.load(hamlyn_model_path, map_location=device)\n",
    "state_dict = prepare_state_dict(state_dict)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "hamlyn_dataset = HamlynDataset(hamlyn_path, 'test', hamlyn_transform)\n",
    "hamlyn_dataloader = DataLoader(hamlyn_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Hamlyn Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SSIM Evaluation:   0%|          | 0/899 [00:00<?, ?batch/s]/Users/louismanestar/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/nn/functional.py:4215: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "SSIM Evaluation:  10%|█         | 91/899 [08:50<1:18:31,  5.83s/batch, left=0.623, right=0.615]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/louismanestar/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/evaluate.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/louismanestar/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc%20Artificial%20Intelligence/Master%27s%20Project/repos/model-evaluation/evaluate.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ssims, spars \u001b[39m=\u001b[39m evaluate_ssim(model, hamlyn_dataloader, hamlyn_save_to, device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/evaluation/hamlyn.py:81\u001b[0m, in \u001b[0;36mevaluate_ssim\u001b[0;34m(model, loader, save_results_to, ssim_weight, device, no_pbar)\u001b[0m\n\u001b[1;32m     79\u001b[0m spars_curve \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39msparsification_curve(true_error, pred_error)\n\u001b[1;32m     80\u001b[0m oracle_curve \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39msparsification_curve(true_error, true_error)\n\u001b[0;32m---> 81\u001b[0m random_curve \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39;49mrandom_sparsification_curve(true_error)\n\u001b[1;32m     83\u001b[0m spars_curves\u001b[39m.\u001b[39mappend((spars_curve, oracle_curve, random_curve))\n\u001b[1;32m     85\u001b[0m average_left_ssim \u001b[39m=\u001b[39m running_left_score \u001b[39m/\u001b[39m ((i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m batch_size)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/MSc Artificial Intelligence/Master's Project/repos/model-evaluation/evaluation/sparsification.py:59\u001b[0m, in \u001b[0;36mrandom_sparsification_curve\u001b[0;34m(oracle_error)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandom_sparsification_curve\u001b[39m(oracle_error: Tensor):\n\u001b[0;32m---> 59\u001b[0m     random_error \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrand_like(oracle_error)\n\u001b[1;32m     60\u001b[0m     \u001b[39mreturn\u001b[39;00m sparsification_curve(oracle_error, random_error)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ssims, spars = evaluate_ssim(model, hamlyn_dataloader, hamlyn_save_to, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSIM Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ssim = sum(ssims) / len(ssims)\n",
    "print(f'Mean SSIM on Hamlyn test set: {mean_ssim}')\n",
    "\n",
    "results_dict['ssim'] = mean_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparsification Plot and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_curves, oracle_curves, random_curves = zip(*spars)\n",
    "\n",
    "pred_curve = np.array(pred_curves).mean(axis=0)\n",
    "oracle_curve = np.array(oracle_curves).mean(axis=0)\n",
    "random_curve = np.array(random_curves).mean(axis=0)\n",
    "\n",
    "error_curve = s.sparsification_error(oracle_curve, pred_curve)\n",
    "\n",
    "ause = s.ause(oracle_curve, pred_curve)\n",
    "aurg = s.aurg(pred_curve, random_curve)\n",
    "\n",
    "figure, (curve_axis, error_axis) = plt.subplots(2, 0)\n",
    "\n",
    "x_axis = np.linspace(0, 1, num=len(oracle_curve))\n",
    "\n",
    "curve_axis.plot(x_axis, oracle_curve, 'r-')\n",
    "curve_axis.plot(x_axis, pred_curve)\n",
    "\n",
    "error_axis.plot(x_axis, error_curve)\n",
    "\n",
    "results_dict['sparsification'] = {\n",
    "    'ause': ause,\n",
    "    'aurg': aurg,\n",
    "    'curves': {\n",
    "        'oracle': oracle_curve,\n",
    "        'predicted': pred_curve,\n",
    "        'random': random_curve,\n",
    "        'error': error_curve\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCARED MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of SCARED Dataset 8: 5 images.\n",
      "Size of SCARED Dataset 9: 5 images.\n"
     ]
    }
   ],
   "source": [
    "scared_model_path = os.path.join('models', 'hamlyn', model_name)\n",
    "scared_save_to = os.path.join(model_save_to, 'scared')\n",
    "\n",
    "state_dict = torch.load(scared_model_path, map_location=device)\n",
    "state_dict = prepare_state_dict(state_dict)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "scared_dataset_8 = SCAREDKeyframesLoader(scared_path, 'test', 8, scared_transform)\n",
    "scared_dataloader_8 = DataLoader(scared_dataset_8, 1, shuffle=True)\n",
    "\n",
    "print(f'Size of SCARED Dataset 8: {len(scared_dataset_8):,} images.')\n",
    "\n",
    "scared_dataset_9 = SCAREDKeyframesLoader(scared_path, 'test', 9, scared_transform)\n",
    "scared_dataloader_9 = DataLoader(scared_dataset_9, 1, shuffle=True)\n",
    "\n",
    "print(f'Size of SCARED Dataset 9: {len(scared_dataset_9):,} images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SCARED Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:23<00:00,  4.63s/batch, mae=tensor(50.6697, dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 8 Keyframe MAEs: [27.28447265338262, 25.89122560226983, 9.90304156224073, 65.7162050259811, 124.55368446595801] mm\n",
      "Mean Absolute Depth on SCARED Dataset 8: 50.669725861966455 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.41s/batch, mae=tensor(76.4943, dtype=torch.float64)] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 9 Keyframe MAEs: [133.9774889871548, 21.60393080556474, 139.509304119105, 12.476071569642508, 74.90452305256555] mm\n",
      "Mean Absolute Depth on SCARED Dataset 9: 76.4942637068065 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "maes_8 = evaluate_keyframes(model, scared_dataloader_8, min_depth, max_depth, device)\n",
    "mean_mae_8 = sum(maes_8) / len(maes_8)\n",
    "print(f'Dataset 8 Keyframe MAEs: {maes_8} mm')\n",
    "print(f'Mean Absolute Depth on SCARED Dataset 8: {mean_mae_8} mm')\n",
    "\n",
    "maes_9 = evaluate_keyframes(model, scared_dataloader_9, min_depth, max_depth, device)\n",
    "mean_mae_9 = sum(maes_9) / len(maes_9)\n",
    "print(f'Dataset 9 Keyframe MAEs: {maes_9} mm')\n",
    "print(f'Mean Absolute Depth on SCARED Dataset 9: {mean_mae_9} mm')\n",
    "\n",
    "results_dict['mae'] = {\n",
    "    'dataset_8': mean_mae_8,\n",
    "    'dataset_9': mean_mae_9\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_path = os.path.join(save_to, model_stem, 'evaluation.json')\n",
    "\n",
    "with open(save_to_path, 'w+') as f:\n",
    "    json.dump(results_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "150b7516945f7222b22aa671f605619702d7b517da28017881bdfb428ff034ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
