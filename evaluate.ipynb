{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import yaml\n",
    "\n",
    "from model import RandomlyConnectedModel\n",
    "\n",
    "from evaluation.hamlyn import evaluate_ssim\n",
    "from evaluation.scared import evaluate_keyframes\n",
    "from evaluation.utils import prepare_state_dict\n",
    "from evaluation import sparsification as s\n",
    "from evaluation import transforms as t\n",
    "\n",
    "from loaders.hamlyn import HamlynDataset\n",
    "from loaders.scared import SCAREDKeyframesLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'test.pt'\n",
    "hamlyn_path = '../da-vinci'\n",
    "scared_path = '../scared'\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') \\\n",
    "    if torch.cuda.is_available() \\\n",
    "    else torch.device('cpu')\n",
    "\n",
    "with open('config.yml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "model = RandomlyConnectedModel(**config).to(device)\n",
    "\n",
    "model_stem = os.path.splitext(model_name)[0]\n",
    "model_save_to = os.path.join('results', model_stem)\n",
    "\n",
    "hamlyn_transform = transforms.Compose([\n",
    "    t.ResizeImage((256, 512)),\n",
    "    t.ToTensor()\n",
    "])\n",
    "\n",
    "scared_transform = transforms.Compose([\n",
    "    t.ResizeImage((1024, 1280)),\n",
    "    t.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamlyn SSIM/Sparsification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlyn_model_path = os.path.join('models', 'hamlyn', model_name)\n",
    "hamlyn_save_to = os.path(model_save_to, 'hamlyn')\n",
    "\n",
    "state_dict = torch.load(hamlyn_model_path).to(device)\n",
    "state_dict = prepare_state_dict(state_dict)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "hamlyn_dataset = HamlynDataset(hamlyn_path, 'test', hamlyn_transform)\n",
    "hamlyn_dataloader = DataLoader(hamlyn_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Hamlyn Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssims, spars = evaluate_ssim(model, hamlyn_dataloader, hamlyn_save_to, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSIM Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ssim = sum(ssims) / len(ssims)\n",
    "print(f'Mean SSIM on Hamlyn test set: {mean_ssim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparsification Plot and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_curves, oracle_curves, random_curves = zip(*spars)\n",
    "\n",
    "pred_curve = np.array(pred_curves).mean(axis=0)\n",
    "oracle_curve = np.array(oracle_curves).mean(axis=0)\n",
    "random_curve = np.array(random_curves).mean(axis=0)\n",
    "\n",
    "ause = s.ause(oracle_curve, pred_curve)\n",
    "aurg = s.aurg(pred_curve, random_curve)\n",
    "\n",
    "figure, (curve_axis, error_axis) = plt.subplots(2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCARED MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scared_model_path = os.path.join('models', 'scared', model_name)\n",
    "scared_save_to = os.path(model_save_to, 'scared')\n",
    "\n",
    "state_dict = torch.load(scared_model_path).to(device)\n",
    "state_dict = prepare_state_dict(state_dict)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "scared_dataset_8 = SCAREDKeyframesLoader(hamlyn_path, 'test', 8, hamlyn_transform)\n",
    "scared_dataloader_8 = DataLoader(scared_dataset_8, batch_size, shuffle=True)\n",
    "\n",
    "scared_dataset_9 = SCAREDKeyframesLoader(hamlyn_path, 'test', 9, hamlyn_transform)\n",
    "scared_dataloader_9 = DataLoader(scared_dataset_9, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SCARED Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes = evaluate_keyframes(model, scared_dataloader_8, scared_save_to, device)\n",
    "mean_mae = sum(maes) / len(maes)\n",
    "print(f'Mean Absolute Depth on SCARED Dataset 8: {mean_mae} mm')\n",
    "\n",
    "maes = evaluate_keyframes(model, scared_dataloader_9, scared_save_to, device)\n",
    "mean_mae = sum(maes) / len(maes)\n",
    "print(f'Mean Absolute Depth on SCARED Dataset 9: {mean_mae} mm')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
